<html>

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0 maximum-scale=1" />
  <!-- https: //github.com/bevyengine/bevy/discussions/3638 -->
  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
      animation: gradient 15s ease infinite;
      height: 100vh;
      width: 100vw;
      display: flex;
      justify-content: center;
      align-items: center;
      position: fixed !important;
    }

    @media (pointer: coarse) {
      /* mobile device */
      canvas {
        position: fixed !important;
        width: 100dvw !important;
        height: 95dvh !important;
        margin-bottom: 5dvh !important;
        padding-bottom: 5dvh !important;
        object-fit: contain;
      }
    }

    @media (pointer: fine), (pointer: none) {
      /* desktop */
      canvas {
        height: 100dvh !important;
        position: fixed !important;
        object-fit: contain;
      }
    }

    @media (pointer: fine) and (any-pointer: coarse) {
      /* touch desktop */
      canvas {
        position: fixed !important;
        height: 100dvh !important;
        object-fit: contain;
      }
    }

    canvas:focus {
      outline: none;
    }
  </style>
</head>

<body>
  <script>
    // the following function keeps track of all AudioContexts and resumes them on the first user
    // interaction with the page. If the function is called and all contexts are already running,
    // it will remove itself from all event listeners.
    (function () {
      // An array of all contexts to resume on the page
      const audioContextList = [];

      // An array of various user interaction events we should listen for
      const userInputEventNames = [
        "click",
        "contextmenu",
        "auxclick",
        "dblclick",
        "mousedown",
        "mouseup",
        "pointerup",
        "touchend",
        "keydown",
        "keyup",
      ];

      // A proxy object to intercept AudioContexts and
      // add them to the array for tracking and resuming later
      self.AudioContext = new Proxy(self.AudioContext, {
        construct(target, args) {
          const result = new target(...args);
          audioContextList.push(result);
          return result;
        },
      });

      // To resume all AudioContexts being tracked
      function resumeAllContexts(_event) {
        let count = 0;

        audioContextList.forEach((context) => {
          if (context.state !== "running") {
            context.resume();
          } else {
            count++;
          }
        });

        // If all the AudioContexts have now resumed then we unbind all
        // the event listeners from the page to prevent unnecessary resume attempts
        // Checking count > 0 ensures that the user interaction happens AFTER the game started up
        if (count > 0 && count === audioContextList.length) {
          userInputEventNames.forEach((eventName) => {
            document.removeEventListener(eventName, resumeAllContexts);
          });
        }
      }

      // We bind the resume function for each user interaction
      // event on the page
      userInputEventNames.forEach((eventName) => {
        document.addEventListener(eventName, resumeAllContexts);
      });
    })();
  </script>
  <script type="module">
    import init from './reptile.js'
    init();
  </script>
</body>

</html>
